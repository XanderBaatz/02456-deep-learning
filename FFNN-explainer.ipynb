{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5f0f89ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import wandb\n",
    "\n",
    "random.seed(27)\n",
    "np.random.seed(27)\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fe6093",
   "metadata": {},
   "source": [
    ">### **This notebook, will support our report with the techincal implementation. Assume that the methods we use are either from week 1-2, and from the \"understanding deep learning\" prince chapter 3-4-5-6-7-8-9. If not, we will specify from where the method is from.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412d1a53",
   "metadata": {},
   "source": [
    "## Section 1: Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6ef1c31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick dataset, \n",
    "ds = \"mnist\"\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "23ea7102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (60000, 784) (60000,)\n",
      "Test shape: (10000, 784) (10000,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mnist_train = datasets.FashionMNIST(root=\"./data\", train=True, download=True, transform=None)\n",
    "mnist_test = datasets.FashionMNIST(root=\"./data\", train=False, download=True, transform=None)\n",
    "\n",
    "X_train = mnist_train.data.to(torch.float32).numpy()\n",
    "y_train = mnist_train.targets.to(torch.int64).numpy()\n",
    "\n",
    "X_test  = mnist_test.data.to(torch.float32).numpy()\n",
    "y_test  = mnist_test.targets.to(torch.int64).numpy()\n",
    "\n",
    "# Normalize the pixel values (important for neural nets)\n",
    "X_train /= 255.0\n",
    "X_test /= 255.0\n",
    "\n",
    "# Flatten\n",
    "X_train = X_train.reshape(-1, np.prod(X_train.shape[1:]))\n",
    "X_test = X_test.reshape(-1, np.prod(X_test.shape[1:]))\n",
    "\n",
    "print(\"Train shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Test shape:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8f692b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (60000, 784) Y_train: (10, 60000)\n",
      "X_test:  (10000, 784) Y_test:  (10, 10000)\n"
     ]
    }
   ],
   "source": [
    "def one_hot_encode(y, num_classes=10):\n",
    "    y_encoded = np.zeros((num_classes, y.size))\n",
    "    y_encoded[y, np.arange(y.size)] = 1\n",
    "    return y_encoded\n",
    "\n",
    "#FashionMNSIT had 10 calsses\n",
    "Y_train = one_hot_encode(y_train, 10)  \n",
    "Y_test  = one_hot_encode(y_test, 10)  \n",
    "\n",
    "\n",
    "print(\"X_train:\", X_train.shape, \"Y_train:\", Y_train.shape)\n",
    "print(\"X_test: \", X_test.shape,  \"Y_test: \",  Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e34116",
   "metadata": {},
   "source": [
    "Since we're dealing with feed forward neural networks (and e.g., not CNNs), we need to flatten the image-tensor for each input. E.g., for a $4 \\times 4$ grayscale image tensor, we flatten it as such:\n",
    "$$\n",
    "x_i =\n",
    "\\begin{bmatrix}\n",
    "1 & 2 & 3 & 4 \\\\\n",
    "5 & 6 & 7 & 8 \\\\\n",
    "9 & 10 & 11 & 12 \\\\\n",
    "13 & 14 & 15 & 16\n",
    "\\end{bmatrix} \\in \\mathbb{R}^{4 \\times 4}\n",
    ", \\qquad\n",
    "\\mathrm{flatten}(x_i) =\n",
    "\\begin{bmatrix}\n",
    "1 & 2 & 3 & 4 &\n",
    "5 & 6 & 7 & 8 &\n",
    "9 & 10 & 11 & 12 &\n",
    "13 & 14 & 15 & 16\n",
    "\\end{bmatrix}^T \\in \\mathbb{R}^{16 \\times 1}\n",
    "$$\n",
    "\n",
    "Do note that this approach is greedy, and might destory spatial features that eg a RGB picture could give. \n",
    "\n",
    "### One-hot encoding of class labels\n",
    "\n",
    "Later, we must calculate the loss using cross-entropy of the softmax output, so each class label must be transformed into a one-hot encoded vector.\n",
    "\n",
    "For a classification problem with \\(C\\) classes, a label\n",
    "\n",
    "\n",
    "$y_i \\in \\{0, 1, \\ldots, C-1\\}$\n",
    "\n",
    "is encoded as\n",
    "\n",
    "$$\n",
    "\\mathrm{onehot}(y_i) =\n",
    "\\begin{bmatrix}\n",
    "0 \\\\ \\vdots \\\\ 1 \\\\ \\vdots \\\\ 0\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "where the component corresponding to the class index \n",
    "\n",
    "> Source: Week 1-2 jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ef8b8b",
   "metadata": {},
   "source": [
    "## Section 2: Feedforward Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a2d5a1",
   "metadata": {},
   "source": [
    "### 2.1: Forward measure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56bfa12",
   "metadata": {},
   "source": [
    "Given input $\\bm{x} \\in \\mathbb{R}^D$ and outputs $\\bm{y} \\in \\mathbb{R}^K$:\n",
    "$$\n",
    "\\bm{x} = \\begin{bmatrix}\n",
    "x_1 \\\\\n",
    "x_2 \\\\\n",
    "\\vdots \\\\\n",
    "x_D\n",
    "\\end{bmatrix}\n",
    ", \\qquad\n",
    "\\bm{y} = \\begin{bmatrix}\n",
    "y_1 \\\\\n",
    "y_2 \\\\\n",
    "\\vdots \\\\\n",
    "y_O\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "we can construct a feed-forward network using basis functions. We can write it as the following recurrence relation.\n",
    "\n",
    "The first layer is:\n",
    "$$\n",
    "a_j^{(1)} = \\sum^{D}_{i=1} w_{j,i}^{(1)} x_i + w_{j,0}^{(1)}, \\qquad z_i^{(0)} = x_i\n",
    "$$\n",
    "\n",
    "where $i = 1, \\dots, D$ and $j = 1, \\dots, D_{1}$, we are essentially just making $D_{1}$ linear combinations of the inputs $x_1, \\dots, x_D$ with $w_{j,i}^{(1)}$ and $w_{j,0}^{(1)}$, which are the weights and biases of the first layer. Here $z_i^{(0)}$ are the hidden units, which in the first layer is just the input.\n",
    "\n",
    "The first layer is then connected to the second layer:\n",
    "$$\n",
    "a_k^{(2)} = \\sum^{D_{1}}_{j=1} w_{k,j}^{(2)} z_j^{(1)} + w_{k,0}^{(2)}, \\qquad z_j^{(1)} = h\\left( a_j^{(1)} \\right)\n",
    "$$\n",
    "\n",
    "with $k = 1, \\dots, D_{2}$.\n",
    "\n",
    "Note here that we use an activation function $h(\\cdot)$ to non-linearize the pre-activations so that they can perform smooth fits of points. These activation functions need to be properly differentiable, so that they can be used in a forward- and backward-propagation chain. That is, both $h(\\cdot) = \\mathrm{forward}(\\cdot)$ and $h'(\\cdot) = \\mathrm{backward}(\\cdot)$ need to be properly defined.\n",
    "\n",
    "We then have the necessary prerequisites to generalize the recurrence relation, so for layers $l = 1, 2, \\dots, L$:\n",
    "\n",
    "$$\n",
    "a_\\alpha^{(l)} = \\sum^{D_{l-1}}_{\\beta=1} w_{\\alpha, \\beta}^{(l)} z_\\beta^{(l-1)} + w_{\\alpha, 0}^{(l)}, \\qquad z_\\beta^{(l-1)} = h\\left( a_\\beta^{(l-1)} \\right)\n",
    "$$\n",
    "\n",
    "where $w_{\\alpha,\\beta}^{(l)}$ are the weights and $w^{(l)}_{\\alpha, 0}$ are the biases of the $l$'th layer.\n",
    "\n",
    "Note here that all $a_\\alpha^{(l)}$ are known as pre-activations and $z_\\beta^{(l)}$ are known as post-activations.\n",
    "\n",
    "Finally, we have the output units:\n",
    "$$\n",
    "y_o(\\bm{x}, \\bm{w}) = z_r^{(L)} = h_L\\left(a_r^{(L)} \\right) = f\\left(a_r^{(L)} \\right)\n",
    "$$\n",
    "\n",
    "in which the \"activation\" function is changed into a prediction function $f$ to get probabilities $p_o \\in [0, 1]$. Most often softmax is used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d38c50",
   "metadata": {},
   "source": [
    "All of this can also be written in vector/matrix notation, which is the kind that we will use in this project (since the vectorization of operations is more efficient):\n",
    "$$\n",
    "\\bm{X} =\n",
    "\\begin{bmatrix}\n",
    "\\vert & \\vert & & \\vert\\\\\n",
    "\\bm{x}^{(1)} & \\bm{x}^{(2)} & \\dots & \\bm{x}^{(m)} \\\\\n",
    "\\vert & \\vert & & \\vert\n",
    "\\end{bmatrix} \\in \\mathbb{R}^{D \\times m}\n",
    "$$\n",
    "where $m$ is number of samples and $D$ is input dimensionality.\n",
    "\n",
    "For a network with $L$ layers $l = 1, 2, \\dots, L$, we have the recurrence relation:\n",
    "$$\n",
    "\\bm{A}^{1} = \\bm{W}^{(1)} \\bm{X} + \\bm{b}^{(1)}, \\qquad \\bm{Z}^{(0)} = \\bm{X}, \\qquad \\bm{W}^{(1)} \\in \\mathbb{R}^{D_1 \\times D}, \\qquad \\bm{b}^{(1)} \\in \\mathbb{R}^{D_1}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\bm{A}^{2} = \\bm{W}^{(2)} \\bm{Z}^{(1)} + \\bm{b}^{(2)}, \\qquad \\bm{Z}^{(1)} = h\\left( \\bm{A}^1 \\right), \\qquad \\bm{W}^{(2)} \\in \\mathbb{R}^{D_2 \\times D_1}, \\qquad \\bm{b}^{(2)} \\in \\mathbb{R}^{D_2}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\bm{A}^{(l)} = \\bm{W}^{(l)} \\bm{Z}^{(l-1)} + \\bm{b}^{(l)}, \\quad \\bm{Z}^{(l-1)} = h\\left( \\bm{A}^{l-1} \\right), \\qquad \\bm{W}^{(l)} \\in \\mathbb{R}^{D_l \\times D_{l-1}}, \\qquad \\bm{b}^{(l)} \\in \\mathbb{R}^{D_l}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\bm{Y}(\\bm{x}, \\bm{w}) = \\bm{Z}^{(L)} = f \\left( \\bm{A}^L \\right)\n",
    "$$\n",
    "\n",
    "where the bias vector $\\bm{b}^{(l)}$ is broadcast across all $l$ units.\n",
    "\n",
    "> Source: Week 1-2, (Understanding Deep Learning, Simon J.D. Prince, chapter 3-4) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d354835d",
   "metadata": {},
   "source": [
    "### 2.2 Activation functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af1320f",
   "metadata": {},
   "source": [
    "Programatically, we just need activation functions to support both forward and backward propagation for a layer. Forward propagation simply uses the base function (non-derivative). Backward propagation uses the first order derivative of the function itself. As discussed previously:\n",
    "$$\n",
    "h(x) = \\mathrm{forward}(x), \\qquad h'(x) = \\mathrm{backward}(x)\n",
    "$$\n",
    "\n",
    "For example, the ReLU activation function:\n",
    "$$\n",
    "\\mathrm{ReLU}(x) = \\max(0,x) =\n",
    "\\begin{cases}\n",
    "0 & \\text{if } x \\leq 0 \\\\\n",
    "x & \\text{if } x > 0\n",
    "\\end{cases}\n",
    ", \\qquad\n",
    "\n",
    "\\mathrm{ReLU}'(x) =\n",
    "\\begin{cases}\n",
    "0 & \\text{if } x \\leq 0 \\\\\n",
    "1 & \\text{if } x > 0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "so we simply just construct an `Activation` function class with `forward` and `backward` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1e3ee31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from NN.activations import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3e8016",
   "metadata": {},
   "source": [
    "### 2.3 Initializer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbb368b",
   "metadata": {},
   "source": [
    "An `Initializer` class to initialize parameters $\\bm{\\Omega}^{(l)} = \\{ \\bm{W}^{(l)}, \\bm{b}^{(l)} \\}$ so that activations maintain stable variance across layers.\n",
    "\n",
    "The key idea (Bishop, UDL book) is that if weights are too large, variance explodes and if it's too small, variance shrinks, so we try to scale parameters such that:\n",
    "$$\n",
    "\\mathrm{Var}\\left(\\bm{A}^{(l)} \\right) \\approx \\mathrm{Var}\\left(\\bm{Z}^{(l-1)} \\right)\n",
    "$$\n",
    "\n",
    "Below we will exemplify this through He initialization using the ReLU activation function ($h(\\cdot) = \\mathrm{ReLU}(\\cdot)$).\n",
    "\n",
    "Assuming biases $b_{\\alpha}^{(l)} = w^{(l)}_{\\alpha, 0}$ are initialized to zero and weights and inputs are i.i.d., and independent of one another.\n",
    "\n",
    "#### Variance of a single pre-activation\n",
    "Consider one hidden unit $\\alpha$ in layer $l$:\n",
    "$$\n",
    "a^{(l)} = \\sum^{D_{l-1}}_{\\beta = 1} w^{(l)}_{\\alpha, \\beta} z^{(l-1)}_{\\beta} + b_{\\alpha}^{(l)}\n",
    "$$\n",
    "\n",
    "Since $b_{\\alpha}^{(l)} = 0$:\n",
    "$$\n",
    "\\mathrm{Var}\\left( a^{(l)}_{\\alpha} \\right) = \\mathrm{Var}\\left( \\sum^{D_{l-1}}_{\\beta = 1} w^{(l)}_{\\alpha, \\beta} z^{(l-1)}_{\\beta} \\right) \n",
    "$$\n",
    "\n",
    "Using that $w^{(l)}_{\\alpha, \\beta}$ and $z^{(l-1)}_{\\beta}$ are independent and also i.i.d. for all $\\beta$:\n",
    "$$\n",
    "\\mathrm{Var}\\left( a^{(l)}_{\\alpha} \\right) = \\sum^{D_{l-1}}_{\\beta = 1} \\mathrm{Var}\\left( w^{(l)}_{\\alpha, \\beta} z^{(l-1)}_{\\beta} \\right) = D_{l-1} \\mathrm{Var}\\left( w^{(l)}_{\\alpha, \\beta} z^{(l-1)}_{\\beta} \\right) \n",
    "$$\n",
    "\n",
    "For two independent random variables:\n",
    "$$\n",
    "\\mathrm{Var}(X Y) = \\mathrm{Var}(X) \\mathrm{Var}(Y) + (\\mathbb{E}[X])^2 \\mathrm{Var}(Y) + (\\mathbb{E}[Y])^2 \\mathrm{Var}(X)\n",
    "$$\n",
    "\n",
    "Applying this, we get:\n",
    "$$\n",
    "\\mathrm{Var}\\left( a^{(l)}_{\\alpha} \\right) = D_{l-1} \\left( \\mathrm{Var}\\left( w_{\\alpha, \\beta}^{(l)} \\right) \\cdot \\mathrm{Var}\\left( z_\\beta^{(l-1)} \\right) + \\left(\\mathbb{E}\\left[ w_{\\alpha, \\beta}^{(l)} \\right] \\right)^2 \\cdot \\mathrm{Var}\\left(z_\\beta^{(l-1)} \\right) + \\left(\\mathbb{E}\\left[ z_\\beta^{(l-1)} \\right] \\right)^2 \\cdot \\mathrm{Var}\\left(w_{\\alpha, \\beta}^{(l)} \\right) \\right)\n",
    "$$\n",
    "\n",
    "Since weights are initialized with $w \\sim \\mathcal{N}(0, \\mathrm{Var}(w))$, we have $\\mathbb{E}\\left[ w_{\\alpha, \\beta}^{(l)} \\right] = 0$, so the above is reduced to:\n",
    "$$\n",
    "\\mathrm{Var}\\left( a^{(l)}_{\\alpha} \\right) = D_{l-1} \\left( \\mathrm{Var}\\left( w_{\\alpha, \\beta}^{(l)} \\right) \\cdot \\mathrm{Var}\\left( z_\\beta^{(l-1)} \\right) + \\left(\\mathbb{E}\\left[ z_\\beta^{(l-1)} \\right] \\right)^2 \\cdot \\mathrm{Var}\\left(w_{\\alpha, \\beta}^{(l)} \\right) \\right)\n",
    "$$\n",
    "\n",
    "Factor out $\\mathrm{Var}\\left(w_{\\alpha, \\beta}^{(l)} \\right)$:\n",
    "$$\n",
    "\\mathrm{Var}\\left( a^{(l)}_{\\alpha} \\right) = D_{l-1} \\mathrm{Var}\\left( w_{\\alpha, \\beta}^{(l)} \\right) \\cdot \\left( \\mathrm{Var}\\left( z_\\beta^{(l-1)} \\right) + \\left(\\mathbb{E}\\left[ z_\\beta^{(l-1)} \\right] \\right)^2 \\right)\n",
    "$$\n",
    "\n",
    "Using the definition of variance we have $\\mathrm{Var}(X) + \\left(\\mathbb{E}\\left[ X \\right] \\right)^2 = \\mathbb{E}\\left[X^2 \\right]$. We can apply this:\n",
    "$$\n",
    "\\mathrm{Var}\\left( a^{(l)}_{\\alpha} \\right) = D_{l-1} \\mathrm{Var}\\left( w_{\\alpha, \\beta}^{(l)} \\right) \\cdot \\left(\\mathbb{E}\\left[ z_\\beta^{(l-1)} \\right]^2 \\right)\n",
    "$$\n",
    "\n",
    "#### Expected squared expectation for ReLU\n",
    "Because $a^{(l-1)}_{\\beta} \\sim \\mathcal{N}\\left(0, \\mathrm{Var}\\left( a^{(l-1)}_{\\beta} \\right) \\right)$ and $z_\\beta^{(l-1)} = \\mathrm{ReLU}\\left( a^{(l-1)}_{\\beta} \\right)$, we obtain:\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\mathbb{E}\\left[\\left(z_\\beta^{(l-1)} \\right)^2 \\right] &= \\int^{\\infty}_{-\\infty} \\left( \\mathrm{ReLU}\\left( a^{(l-1)}_{\\beta} \\right) \\right)^2 \\cdot f_{a^{(l-1)}_{\\beta}} \\left( a_\\beta^{(l-1)} \\right) \\, \\mathrm{d}\\left(a_\\beta^{(l-1)} \\right) \\\\\n",
    "&= \\int^{\\infty}_{0} \\left( a^{(l-1)}_{\\beta} \\right)^2 \\cdot f_{a^{(l-1)}_{\\beta}} \\left( a_\\beta^{(l-1)} \\right) \\, \\mathrm{d}\\left(a_\\beta^{(l-1)} \\right) \\qquad \\text{since } \\mathrm{ReLU} = 0 \\text{ for } a < 0 \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Using symmetry:\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\mathbb{E}\\left[\\left(z_\\beta^{(l-1)} \\right)^2 \\right] &= \\frac{1}{2} \\int^{\\infty}_{-\\infty} \\left( a^{(l-1)}_{\\beta} \\right)^2 \\cdot f_{a^{(l-1)}_{\\beta}} \\left( a_\\beta^{(l-1)} \\right) \\, \\mathrm{d}\\left(a_\\beta^{(l-1)} \\right) \\\\\n",
    "&= \\frac{1}{2} \\mathbb{E}\\left[ \\left( a^{(l-1)}_{\\beta} \\right)^2 \\right] \\\\\n",
    "&= \\frac{1}{2} \\mathrm{Var}\\left( a^{(l-1)}_{\\beta} \\right) \\qquad \\text{since zero mean} \n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "So for ReLU, we have:\n",
    "$$\n",
    "\\mathrm{Var}\\left( z^{(l-1)}_{\\beta} \\right) = \\mathbb{E}\\left[\\left(z_\\beta^{(l-1)} \\right)^2 \\right] = \\frac{1}{2} \\mathrm{Var}\\left( z^{(l-1)}_{\\beta} \\right)\n",
    "$$\n",
    "\n",
    "Returning to the variance of the pre-activation:\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\mathrm{Var}\\left( a^{(l)}_{\\alpha} \\right) &= D_{l-1} \\mathrm{Var}\\left( w_{\\alpha, \\beta}^{(l)} \\right) \\cdot \\left(\\mathbb{E}\\left[ z_\\beta^{(l-1)} \\right]^2 \\right) \\\\\n",
    "&= D_{l-1} \\mathrm{Var}\\left( w_{\\alpha, \\beta}^{(l)} \\right) \\cdot \\left( \\frac{1}{2} \\mathrm{Var}\\left( z^{(l-1)}_{\\beta} \\right) \\right) \\\\\n",
    "&= \\frac{1}{2} D_{l-1} \\mathrm{Var}\\left( w_{\\alpha, \\beta}^{(l)} \\right) \\mathrm{Var}\\left( z^{(l-1)}_{\\beta} \\right)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "#### Variance across all layers\n",
    "We relate this to the recurrence relation defined earlier. Recall that $\\bm{Z}^{(0)} = \\bm{X}$, then for $l = 1, \\dots, L$:\n",
    "$$\n",
    "\\mathrm{Var}\\left( \\bm{A}^{(l)} \\right) = D_{l-1} \\mathrm{Var}\\left( \\bm{W}^{(l)} \\right) \\mathrm{Var}\\left( \\bm{Z}^{(l-1)} \\right)\n",
    "$$\n",
    "\n",
    "and for ReLU we have $\\mathrm{Var}\\left( \\bm{Z}^{(l)} \\right) = \\frac{1}{2} \\mathrm{Var}\\left( \\bm{A}^{(l)} \\right)$:\n",
    "$$\n",
    "\\mathrm{Var}\\left( \\bm{A}^{(l)} \\right) = D_{l-1} \\mathrm{Var}\\left( \\bm{W}^{(l)} \\right) \\mathrm{Var}\\left( \\bm{Z}^{(l-1)} \\right)\n",
    "$$\n",
    "\n",
    "so recursively, for the last layer:\n",
    "$$\n",
    "\\mathrm{Var}\\left( \\bm{A}^{(L)} \\right) = \\mathrm{Var}\\left( \\bm{Z}^{(0)} \\right) \\prod^{L}_{l=1} \\left( \\frac{1}{2} D_{l-1} \\mathrm{Var}\\left( \\bm{W}^{(l)} \\right) \\right)\n",
    "$$\n",
    "\n",
    "#### Weight initialization\n",
    "To maintain stable variance while propagating layers we must have:\n",
    "$$\n",
    "\\frac{1}{2} D_{l-1} \\mathrm{Var}\\left( \\bm{W}^{(l)} \\right) \\approx 1\n",
    "$$\n",
    "\n",
    "Solving for variance:\n",
    "$$\n",
    "\\mathrm{Var}\\left( \\bm{W}^{(l)} \\right) \\approx \\frac{2}{D_{l-1}}\n",
    "$$\n",
    "\n",
    "Inserting this into the distribution:\n",
    "$$\n",
    "W^{(l)}_{\\alpha, \\beta} \\sim \\mathcal{N}\\left( 0, \\frac{2}{D_{l-1}} \\right)\n",
    "$$\n",
    "\n",
    "which gives He initialization. \n",
    "\n",
    "Note here that $D_{l-1}$ is equivalent to `n_in`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3351c64",
   "metadata": {},
   "source": [
    "> Source is chapter 7 in prince, bishop UDL book from signals & data course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0d395b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from NN.initializer import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98305e4",
   "metadata": {},
   "source": [
    "### 2.4 Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f8ecaf",
   "metadata": {},
   "source": [
    "We now construct a `Layer` class to handle all forward and backward propagation. We then create a `DenseLayer` which is synonymous with a fully connected layer, i.e. a layer in which every neuron (hidden unit) in layer $l$ is connected with every neuron in $l-1$.\n",
    "\n",
    "Here we also make use of the `Initializer` and `Activation` classes we made. Furthermore, we have also introduced L2 regularization to encourage smoother weights (UDL book)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3e41bfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from NN.denseLayer import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e84911",
   "metadata": {},
   "source": [
    "Quick test, output as a probability distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "548adef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.09870661 0.10201467 0.10157728 0.10124532 0.10160944 0.09780518\n",
      " 0.09417268 0.09979802 0.10433105 0.09873976]\n",
      "0.9999999999999999\n"
     ]
    }
   ],
   "source": [
    "layer1 = DenseLayer(\n",
    "    n_in=X_train.shape[1],\n",
    "    n_out=15,\n",
    "    activation=ReLU(),\n",
    "    initializer=HeInitializer()\n",
    ")\n",
    "output_layer = DenseLayer(\n",
    "    n_in=15,\n",
    "    n_out=10,\n",
    "    activation=Softmax(),\n",
    "    initializer=NormalInitializer() #In this we just set initialiser to normal, however given None, it will automaticly detect what initialiser to use\n",
    ")\n",
    "\n",
    "A1 = layer1.forward(X_train.T)      # ReLU\n",
    "A2 = output_layer.forward(layer1.Z) # SoftMax\n",
    "\n",
    "sample_probs = A2[:, 0]      # first sample\n",
    "print(sample_probs)\n",
    "print(sum(sample_probs))     # should be 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1d4041aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DenseLayer(784 -> 15, Activation=ReLU)\n",
      "Weights shape: (15, 784), min: -0.181879, max: 0.193472, mean: -0.000298\n",
      "Biases shape: (15, 1), min: 0.000000, max: 0.000000, mean: 0.000000\n"
     ]
    }
   ],
   "source": [
    "print(layer1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda12a29",
   "metadata": {},
   "source": [
    "### 2.5 Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8181f2f",
   "metadata": {},
   "source": [
    "Here we have a class for `Loss` functions. We've implemented `CrossEntropyLoss` for multi-class classification. Again, we follow the same design-paradigm with `forward` and `backward` class methods.\n",
    "\n",
    "We can derive the Cross Entropy loss function as follows. We have a training set $\\mathcal{D} = \\{ (\\bm{x}_n, \\bm{t}_n) : n = 1, \\dots, N \\}$. The loss (or error) is then a measure of how far $\\bm{y}(\\bm{x}, \\bm{w})$ is from the target data.\n",
    "\n",
    "#### Softmax\n",
    "For a minibatch of size $m$, the final pre-activations are:\n",
    "$$\n",
    "\\bm{A}^{(L)} \\in \\mathbb{R}^{K \\times m}\n",
    "$$\n",
    "\n",
    "where each column $\\bm{a}^{(L)}_n$ is the $K$-vector of logits for example $n$.\n",
    "\n",
    "In case we wanted to use the whole dataset, we'd set $m=N$.\n",
    "\n",
    "We define the softmax output:\n",
    "$$\n",
    "\\bm{Y}(\\bm{x}, \\bm{w}) = \\mathrm{softmax}\\left( \\bm{A}^{(L)} \\right), \\qquad \\bm{Y}_{k,n} = \\frac{\\exp\\left( A^{(L)}_{k,n} \\right)}{\\sum^{K}_{j=1} \\exp\\left( A^{(L)}_{j,n} \\right)}\n",
    "$$\n",
    "\n",
    "Targets for the minibatch are then encoded as one-hot (or probabilities) in:\n",
    "$$\n",
    "\\bm{T} \\in \\mathbb{R}^{K \\times m}, \\qquad T_{k,n} \\in \\{ 0, 1 \\}, \\qquad \\sum^{K}_{k=1} T_{k,n} = 1\n",
    "$$\n",
    "\n",
    "#### Cross Entropy loss\n",
    "The likelihood for one example $n$ under the model is:\n",
    "$$\n",
    "P(\\bm{t}_n \\mid \\bm{x}_n, \\bm{w}) = \\prod^{K}_{k=1} \\left[ \\bm{Y}_k(\\bm{x}_n) \\right]^{T_{k,n}}\n",
    "$$\n",
    "\n",
    "Using negative log likelihood, we get the loss (for the whole minibatch):\n",
    "$$\n",
    "L(\\bm{w}) = -\\log\\left( \\prod^{m}_{n=1} \\left( \\prod^{K}_{k=1} \\left[ \\bm{Y}_k(\\bm{x}_n) \\right]^{T_{k,n}} \\right) \\right) = - \\sum^{m}_{n=1} \\sum^{K}_{k=1} T_{k,n} \\log\\left( \\bm{Y}_{k,n} \\right)\n",
    "$$\n",
    "\n",
    "The batched-average loss:\n",
    "$$\n",
    "L(\\bm{w}) = - \\frac{1}{m} \\sum^{m}_{n=1} \\sum^{K}_{k=1} T_{k,n} \\log\\left( \\bm{Y}_{k,n} \\right)\n",
    "$$\n",
    "\n",
    "#### Derivative w.r.t. logits\n",
    "We need the gradient $\\frac{\\partial L}{\\partial A^{(L)}_{j,n}}$ for a single sample $n$. First we calculate the loss:\n",
    "$$\n",
    "L^{(n)} = -\\sum^{K}_{k=1} t_k \\log(y_k), \\qquad y_k = \\frac{\\exp\\left( A^{(L)}_{k,n} \\right)}{\\sum_{j} \\exp\\left( A^{(L)}_{j,n} \\right)}\n",
    "$$\n",
    "\n",
    "We get the result:\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial A^{(L)}_{j,n}} = Y_{j,n} - T_{j,n}\n",
    "$$\n",
    "\n",
    "for each class index $j$.\n",
    "\n",
    "Since we do this vectorized, we have gradient:\n",
    "$$\n",
    "\\bm{G} := \\frac{\\partial L}{\\partial \\bm{A}^{(L)}} \\in \\mathbb{R}^{K \\times m}\n",
    "$$\n",
    "\n",
    "and elementwise we have:\n",
    "$$\n",
    "\\bm{G} = \\frac{1}{m} (\\bm{Y} - \\bm{T})\n",
    "$$\n",
    "\n",
    "#### Gradients for final layer\n",
    "The final layer will output $\\bm{A}^{(L)} = \\bm{W}^{(L)} \\bm{Z}^{(L-1)} + \\bm{b}^{(L)}$ where $\\bm{Z}^{(L-1)} \\in \\mathbb{R}^{D_{L-1} \\times m}$ are activations from the previous layer.\n",
    "\n",
    "Using $\\bm{G} = \\frac{\\partial L}{\\partial \\bm{A}^{(L)}} = \\frac{1}{m} (\\bm{Y} - \\bm{T})$, the gradients we get are:\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial \\bm{W}^{(L)}} = \\bm{G} \\left(\\bm{Z}^{(L-1)}\\right)^T \\in \\mathbb{R}^{K \\times D_{L-1}}, \\qquad \\frac{\\partial L}{\\partial \\bm{b}^{(L)}} = \\bm{G} \\bm{1}_m = \\frac{1}{m} \\sum^{m}_{n=1} (\\bm{Y}_{:,n} - \\bm{T}_{:,n}) \\in \\mathbb{R}^{K}\n",
    "$$\n",
    "\n",
    "If L2 regularization is included, simply add $\\lambda \\bm{W}^{(L)}$ to $\\frac{\\partial L}{\\partial \\bm{W}^{(L)}}$.\n",
    "\n",
    "The gradient we pass to the previous layer is then:\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial \\bm{Z}^{(L-1)}} = \\left( \\bm{W}^{(L)} \\right)^T \\bm{G}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ef3edbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from NN.loss import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe40646b",
   "metadata": {},
   "source": [
    "### 2.6 Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887d72ac",
   "metadata": {},
   "source": [
    "The goal of an `Optimizer` is to find the parameters that minimize the loss. It uses the gradients with respect to the parameters $\\bm{W}$ and $\\bm{b}$ to do so. At each iteration it updates the weights wrt. a defined magnitude $\\alpha$, that decides how much the parameters will change, and the gradients:\n",
    "$$\n",
    "\\bm{W} \\leftarrow \\bm{W} - \\alpha_{\\bm{W}} \\cdot \\frac{\\partial L}{\\partial \\bm{W}}, \\qquad \\bm{b} \\leftarrow \\bm{b} - \\alpha_{\\bm{b}} \\cdot \\frac{\\partial L}{\\partial \\bm{b}}\n",
    "$$\n",
    "\n",
    "Here we implemented `SGD` (stochastic gradient descent), without momentum, which has a fixed step size and `Adam` (adaptive moment estimation). \n",
    "\n",
    "The main differences between the two is that SGD has a single learning rate for all parameters, where Adam has multiple learning rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "87e2bff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from NN.optimizer import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5923b8e",
   "metadata": {},
   "source": [
    "### 2.7 Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5790d65d",
   "metadata": {},
   "source": [
    "Forward pass:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b8e26815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.10160114 0.10376081 0.10058171 ... 0.103397   0.10109125 0.10073226]\n",
      " [0.0975293  0.09456485 0.09922755 ... 0.09651562 0.09879197 0.09916673]\n",
      " [0.09967127 0.099807   0.10045652 ... 0.10286542 0.09982896 0.10157053]\n",
      " ...\n",
      " [0.09819887 0.09744936 0.09950998 ... 0.09834698 0.09862352 0.09985518]\n",
      " [0.10258447 0.10136785 0.10077615 ... 0.10112799 0.10165818 0.10006722]\n",
      " [0.10341411 0.10340475 0.10111761 ... 0.10259457 0.10160808 0.10060068]]\n"
     ]
    }
   ],
   "source": [
    "NN = [\n",
    "    DenseLayer(X_train.shape[1], 15, activation=ReLU(), initializer=HeInitializer()),\n",
    "    DenseLayer(15, 10, activation=Softmax(), initializer=NormalInitializer())\n",
    "]\n",
    "\n",
    "def forward(input, network):\n",
    "    x = input.T  # transpose: (features, batch)\n",
    "    for layer in network:\n",
    "        x = layer.forward(x)\n",
    "    return x\n",
    "\n",
    "print(forward(X_train, NN))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c77b79",
   "metadata": {},
   "source": [
    "Backward pass:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c2a510d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.63278891e-06, -1.49753718e-05, -1.49928429e-05, ...,\n",
       "         1.67267691e-06, -1.49824100e-05,  1.66683685e-06],\n",
       "       [ 1.65322078e-06,  1.66005120e-06,  1.66127710e-06, ...,\n",
       "         1.65071529e-06,  1.65871277e-06,  1.66149478e-06],\n",
       "       [ 1.69289123e-06,  1.66742823e-06,  1.67153133e-06, ...,\n",
       "         1.65839722e-06,  1.66462667e-06,  1.66707221e-06],\n",
       "       ...,\n",
       "       [ 1.59947325e-06,  1.61843175e-06,  1.64750506e-06, ...,\n",
       "         1.61983475e-06,  1.64341427e-06,  1.65749930e-06],\n",
       "       [ 1.68355851e-06,  1.65492178e-06,  1.66957073e-06, ...,\n",
       "         1.67452976e-06,  1.66902200e-06,  1.67287168e-06],\n",
       "       [-1.50164237e-05,  1.66584056e-06,  1.66617074e-06, ...,\n",
       "         1.69045966e-06,  1.66778871e-06,  1.66165003e-06]],\n",
       "      shape=(10, 60000))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN = [\n",
    "    DenseLayer(X_train.shape[1], 15, activation=ReLU(), initializer=HeInitializer()),\n",
    "    DenseLayer(15, 10, activation=Softmax(), initializer=NormalInitializer())\n",
    "]\n",
    "\n",
    "output = forward(X_train, NN)\n",
    "\n",
    "loss_fn = CrossEntropyLoss()\n",
    "dA = loss_fn.backward(A=output, Y=Y_train)\n",
    "\n",
    "dA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d5b14030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0 \n",
      " DenseLayer(784 -> 15, Activation=ReLU)\n",
      "Weights shape: (15, 784), min: -0.198701, max: 0.205178, mean: 0.000043\n",
      "Biases shape: (15, 1), min: 0.000000, max: 0.000000, mean: 0.000000\n",
      "Layer 1 \n",
      " DenseLayer(15 -> 10, Activation=Softmax)\n",
      "Weights shape: (10, 15), min: -0.026312, max: 0.032072, mean: -0.000360\n",
      "Biases shape: (10, 1), min: 0.000000, max: 0.000000, mean: 0.000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print('Layer', i, '\\n', NN[i]) for i in range(len(NN))] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe55e464",
   "metadata": {},
   "source": [
    "## Section 3 Train loop, batching and wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8ead9707",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getAPI import retrieveApi #Retrives our personal API. Gitignore this.\n",
    "\n",
    "os.environ['WANDB_API_KEY'] = retrieveApi()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274c8b0b",
   "metadata": {},
   "source": [
    "We implement mini-batching for the gradient descent by taking inspiration from this source\n",
    "> https://medium.com/@lomashbhuva/mini-batch-gradient-descent-a-comprehensive-guide-ba27a6dc4863"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f379c679",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(preds, Y):\n",
    "    \"\"\"\n",
    "    preds: (classes, batch)\n",
    "    Y: one-hot labels (classes, batch)\n",
    "    \"\"\"\n",
    "    pred_labels = np.argmax(preds, axis=0)\n",
    "    true_labels = np.argmax(Y, axis=0)\n",
    "    return np.mean(pred_labels == true_labels)\n",
    "\n",
    "\n",
    "##TRAINING WITH MINI BATCHING\n",
    "\n",
    "def train(X, Y, layers, loss_fn, optimizer, epochs=5, batch_size=64):\n",
    "    m = X.shape[0]\n",
    "    losses = []\n",
    "    accs = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        #Here we shuffle data to make it random. \n",
    "        perm = np.random.permutation(m)\n",
    "        X_shuffled = X[perm].T\n",
    "        Y_shuffled = Y[:, perm]\n",
    "\n",
    "        for i in range(0, m, batch_size):\n",
    "            X_batch = X_shuffled[:, i:i+batch_size]\n",
    "            Y_batch = Y_shuffled[:, i:i+batch_size]\n",
    "\n",
    "            # Forward\n",
    "            A = X_batch\n",
    "            for layer in layers:\n",
    "                A = layer.forward(A)\n",
    "\n",
    "            # Loss\n",
    "            loss = loss_fn.forward(A, Y_batch)\n",
    "\n",
    "            # Backward\n",
    "            dA = loss_fn.backward(A, Y_batch)\n",
    "            for layer in reversed(layers):\n",
    "                dA, dW, db = layer.backward(dA)\n",
    "                optimizer.update(layer, dW, db)\n",
    "\n",
    "        # Compute accuracy on all data\n",
    "        A_full = X.T\n",
    "        for layer in layers:\n",
    "            A_full = layer.forward(A_full)\n",
    "        acc = accuracy(A_full, Y)\n",
    "\n",
    "\n",
    "        epoch_acc = accuracy(A_full, Y)\n",
    "        losses.append(loss)\n",
    "        accs.append(epoch_acc)\n",
    "\n",
    "\n",
    "        wandb.log({\n",
    "            \"loss\": loss,\n",
    "            \"accuracy\": acc,\n",
    "            \"epoch\": epoch + 1\n",
    "        })\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}  loss={loss:.4f}  acc={epoch_acc:.4f}\")\n",
    "\n",
    "    return losses, accs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f379c679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define network architecture, small example\n",
    "layers = [\n",
    "    DenseLayer(X_train.shape[1], 128, activation=ReLU(), initializer=None),\n",
    "    DenseLayer(128, 10, activation=Softmax(), initializer=None) #NOTE None makes it automatic. \n",
    "]\n",
    "\n",
    "# Optimizer\n",
    "opt = SGD(learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4224e316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">mnist_demo</strong> at: <a href='https://wandb.ai/xanderbaatz-danmarks-tekniske-universitet-dtu/numpy_nn/runs/y4q9ew84' target=\"_blank\">https://wandb.ai/xanderbaatz-danmarks-tekniske-universitet-dtu/numpy_nn/runs/y4q9ew84</a><br> View project at: <a href='https://wandb.ai/xanderbaatz-danmarks-tekniske-universitet-dtu/numpy_nn' target=\"_blank\">https://wandb.ai/xanderbaatz-danmarks-tekniske-universitet-dtu/numpy_nn</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251201_143658-y4q9ew84/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspaces/02456-deep-learning/wandb/run-20251201_144300-pbia6pw7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/xanderbaatz-danmarks-tekniske-universitet-dtu/numpy_nn/runs/pbia6pw7' target=\"_blank\">mnist_demo</a></strong> to <a href='https://wandb.ai/xanderbaatz-danmarks-tekniske-universitet-dtu/numpy_nn' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/xanderbaatz-danmarks-tekniske-universitet-dtu/numpy_nn' target=\"_blank\">https://wandb.ai/xanderbaatz-danmarks-tekniske-universitet-dtu/numpy_nn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/xanderbaatz-danmarks-tekniske-universitet-dtu/numpy_nn/runs/pbia6pw7' target=\"_blank\">https://wandb.ai/xanderbaatz-danmarks-tekniske-universitet-dtu/numpy_nn/runs/pbia6pw7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20  loss=2.2915  acc=0.3913\n",
      "Epoch 2/20  loss=2.2769  acc=0.3906\n",
      "Epoch 3/20  loss=2.2477  acc=0.3603\n",
      "Epoch 4/20  loss=2.1926  acc=0.3367\n",
      "Epoch 5/20  loss=2.1375  acc=0.3299\n",
      "Epoch 6/20  loss=2.0284  acc=0.3605\n",
      "Epoch 7/20  loss=1.9173  acc=0.3853\n",
      "Epoch 8/20  loss=1.7938  acc=0.4089\n",
      "Epoch 9/20  loss=1.7459  acc=0.4695\n",
      "Epoch 10/20  loss=1.5984  acc=0.5236\n",
      "Epoch 11/20  loss=1.4673  acc=0.5555\n",
      "Epoch 12/20  loss=1.5008  acc=0.5788\n",
      "Epoch 13/20  loss=1.2985  acc=0.5879\n",
      "Epoch 14/20  loss=1.3491  acc=0.5982\n",
      "Epoch 15/20  loss=1.2186  acc=0.6060\n",
      "Epoch 16/20  loss=1.2071  acc=0.6158\n",
      "Epoch 17/20  loss=1.1817  acc=0.6199\n",
      "Epoch 18/20  loss=1.1739  acc=0.6262\n",
      "Epoch 19/20  loss=0.9764  acc=0.6360\n",
      "Epoch 20/20  loss=1.0258  acc=0.6431\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    project=\"numpy_nn\",\n",
    "    name=\"mnist_demo\",\n",
    "    config={\n",
    "        \"epochs\": 20,\n",
    "        \"batch_size\": 128,\n",
    "        \"learning_rate\": 0.01,\n",
    "        \"optimizer\": \"SGD\",\n",
    "        \"loss\": \"CrossEntropy\"\n",
    "    }\n",
    ")\n",
    "\n",
    "losses, accs = train(\n",
    "    X_train,\n",
    "    Y_train,\n",
    "    layers,\n",
    "    CrossEntropyLoss(),\n",
    "    opt,\n",
    "    epochs=20,\n",
    "    batch_size=128\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(losses)\n",
    "plt.title(\"Loss Curve\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(accs)\n",
    "plt.title(\"Accuracy Curve\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3c7364",
   "metadata": {},
   "source": [
    "### Conclusion: We have now created a modular FFN, where we can change hyperparameters, and log using wandb. Now please go to the trainer.ipynb for the hyper parameter study. In this trainer.ipynb, we will create cross validation with sweeps in wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafa8318",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
